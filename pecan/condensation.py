"""Topology-based diffusion condensation scheme."""

import argparse
import datetime
import logging
import os
import sys

import numpy as np

from sklearn.metrics.pairwise import euclidean_distances
from sklearn.metrics.pairwise import rbf_kernel

from yaspin import yaspin
from yaspin.spinners import Spinners

import data

from callbacks import CalculateBifiltration
from callbacks import CalculateDiffusionHomology
from callbacks import CalculatePersistentHomology

from kernels import get_kernel_fn

from utilities import estimate_epsilon
from utilities import generate_output_filename


class DiffusionCondensation:
    """Generic diffusion condensation functor.

    This class permits running a generic diffusion condensation process
    on a data set. It supports certain hooks by which additional steps,
    such as further processing operations, may be integrated.
    """

    def __init__(
        self,
        callbacks=[],
        prefix='data_',
        kernel_fn=None,
    ):
        """Initialise new instance and register callbacks.

        Parameters
        ----------
        callbacks : list of callable
            Function objects (functors) that will be called during each
            iteration. Every functor instance must satisfy a signature,
            as described below::

                callback(i, X, P, D)

            Where `i` is the current time step, `X` is the current data,
            `P` is the current diffusion operator, and `D` is a distance
            matrix between data points (using the Euclidean distance).

        prefix : str
            Indicates the prefix to be used for storing individual time
            steps. If set to `X`, the first key of the diffusion
            condensation process will be called `X_t_0`.

        kernel_fn : callable (optional)
            If set, overrides kernel functions to be used for the
            affinity matrix calculation. The function needs to be
            able to calculate pairwise affinities for a matrix. A
            keyword argument `epsilon` must be supported, but can
            also be ignored within the function.
        """
        self.callbacks = callbacks
        self.prefix = prefix
        self.kernel_fn = kernel_fn

        if self.kernel_fn is None:
            self.kernel_fn = self.make_affinity_matrix

    def __call__(self, X, epsilon):
        """Run condensation process for a given data set."""
        n = X.shape[0]

        # Denotes the previous density measurement, which is initialised to
        # an identity matrix depending on the number of samples, as well as
        # the previously-observed difference, which has to be set to inf in
        # order to be suitable.
        Q_prev = np.identity(n)
        Q_diff = np.inf

        # We only work on a copy of the data set since we shift everything,
        # i.e. points start changing their positions.
        X = X.copy()

        i = 0
        j = -2

        # Will store the data set per iteration to check whether the
        # implementation works as expected.
        data = {
            self.prefix + 't_0': X.copy(),
            'P_t_0': np.identity(n),
        }

        for callback in self.callbacks:
            callback(i, X, np.identity(n), euclidean_distances(X))

        logging.info('Started diffusion condensation process')

        with yaspin(spinner=Spinners.dots) as sp:
            while i - j > 1:

                j = i

                while Q_diff >= 1e-4:

                    sp.text = f'Iteration {i}'

                    # This signals that we want to perform an additional
                    # operation of diffusion here.
                    i += 1

                    # Process new merges by checking whether their respective
                    # label assignments changed.
                    D = euclidean_distances(X)

                    A = self.kernel_fn(X, epsilon)
                    Q = np.sum(A, axis=1)
                    K = np.diag(1.0 / Q) @ A @ np.diag(1.0 / Q)
                    P = np.diag(1.0 / np.sum(K, axis=1)) @ K

                    # Store diffusion operator
                    data[f'P_t_{i}'] = P

                    for callback in self.callbacks:
                        callback(i, X, P, D)

                    X = P @ X

                    # Store new variant of the data set for the current
                    # iteration at time $i$.
                    data[f'{self.prefix}t_{i}'] = X.copy()

                    Q_diff = np.max(Q - Q_prev)
                    Q_prev = Q

                epsilon *= 2
                Q_diff = np.inf

        # Update data dictionary with all the data generated by the
        # callback.
        for callback in self.callbacks:
            data = callback.finalise(data)

        logging.info('Finished diffusion condensation process')
        return data

    @staticmethod
    def make_affinity_matrix(X, epsilon):
        """Calculate affinity matrix.

        This functions calculates an affinity matrix from an input matrix.
        The input matrix is required to be of shape $(n, d)$, with $n$ and
        $d$ representing the number of samples and dimensions.

        Parameters
        ----------
        X : np.array of shape (n, m)
            Input matrix with `n` samples and `m` features.

        epsilon : float
            Smoothing parameter for the kernel calculation.
        """
        return rbf_kernel(X, gamma=1.0 / epsilon)


if __name__ == '__main__':

    # Set up logging to obtain some nice output information, runtime,
    # and much more.
    logging.basicConfig(
        format='%(asctime)s.%(msecs)03d  [%(levelname)-10s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        level=logging.INFO
    )

    parser = argparse.ArgumentParser()

    parser.add_argument(
        '-c', '--callbacks',
        default=None,
        nargs='+',
        help='Specifies names for callbacks to use. The full callback class '
             'name must be provided.'
    )

    parser.add_argument(
        '-d', '--data',
        default='hyperuniform_ellipse',
        type=str,
        help='Select data set generator routine or filename to load.'
    )

    parser.add_argument(
        '-n', '--num-samples',
        default=128,
        type=int
    )

    parser.add_argument(
        '-e', '--epsilon',
        # TODO: ensure that this makes sense and be adjusted more
        # easily, depending on the number of points etc.
        default=np.nan,
        type=float,
    )

    parser.add_argument(
        '-k', '--kernel',
        default='gaussian',
        type=str,
        choices=['alpha', 'gaussian', 'laplacian', 'constant', 'box'],
        help='Sets kernel to use for diffusion condensation process.'
    )

    parser.add_argument(
        '-f', '--force',
        action='store_true',
        help='If set, overwrites existing output files.'
    )

    parser.add_argument(
        '-o', '--output',
        default='.',
        type=str,
        help='Output directory (meaning that the filename will be '
             'generated automatically) or output filename.'
    )

    parser.add_argument(
        '-s', '--seed',
        type=int,
        default=None,
        help='Set random seed to ensure reproducibility.'
    )

    # TODO: implement effects of this
    parser.add_argument(
        '--noise',
        type=float,
        default=0.0,
        help='Noise level to add to the data set'
    )

    parser.add_argument(
        '-b', '--beta',
        default=1.0,
        type=float,
        help='Beta parameter for distributions. Will be used whenever '
             'it is appropriate.'
    )

    parser.add_argument(
        '-r',
        default=0.5,
        type=float,
        help='Inner radius for annuli and related data sets. Will be used '
             'whenever it is appropriate.'
    )

    parser.add_argument(
        '-R',
        default=1.0,
        type=float,
        help='Outer radius for annuli and related data sets. Will be used '
             'whenever it is appropriate.'
    )

    parser.add_argument(
        '-K',
        default=0.0,
        type=float,
        help='Curvature for sampling points on disks of const. curvature. Will be used '
             'whenever it is appropriate.'
    )

    args = parser.parse_args()
    this = sys.modules[__name__]

    if args.seed is None:
        # Not the best way to seed the random generator, but this
        # ensures that we obtain different results per run.
        seed = int(datetime.datetime.now().timestamp())
    else:
        seed = args.seed

    # Client specified a file instead of generator function. Let's use
    # this. The unfortunate issue with this is that generators must be
    # named differently than files...
    if os.path.isfile(args.data):
        X = np.loadtxt(args.data)
    else:
        # Search for a generator routine, as requested by the client. This
        # does not fail gracefully.
        generator = getattr(data, args.data)

        logging.info(f'Using generator routine {generator}')

        X, C = generator(
            args.num_samples,
            random_state=seed,
            r=args.r,
            R=args.R,
            K=args.K,
            beta=args.beta,
        )

    if np.isnan(args.epsilon):
        args.epsilon = estimate_epsilon(X)

        logging.info(
            f'Epsilon parameter has not been set. Estimating '
            f'it as {args.epsilon:.4f}.'
        )

    logging.info(f'Data set: {args.data}')
    logging.info(f'Number of samples: {args.num_samples}')
    logging.info(f'Epsilon: {args.epsilon:.4f}')

    # User specified an existing directory, so we generate a filename
    # automatically and store everything in it.
    if os.path.isdir(args.output):
        # Store data set. The name of output file is generated automatically
        # to account for conditions of the environment.

        output_filename = generate_output_filename(args, seed)
        output_filename = os.path.join(args.output, output_filename)

    # Just use the user-provided output path.
    else:
        output_filename = args.output

        # Check whether we have to create a directory.
        if (dirname := os.path.dirname(output_filename)):
            os.makedirs(dirname, exist_ok=True)

    # Check early on whether we have to do something or not.
    if os.path.exists(output_filename) and not args.force:
        logging.info(
            'Refusing to overwrite existing file. Use `--force` to change '
            'this behaviour.'
        )

        sys.exit(-1)

    # Get default callbacks if user did not provide anything else. Feel
    # free to change this.
    if args.callbacks is None:
        callbacks = [
            CalculateDiffusionHomology(),
            CalculatePersistentHomology(),
            CalculateBifiltration(),
        ]
    else:
        import callbacks as cb

        # Initialise callbacks with default parameters.
        callbacks = [
            getattr(cb, callback, None)() for callback in args.callbacks
        ]

        # Silently ignore all callbacks that were not found.
        callbacks = [
            callback for callback in callbacks if callback is not None
        ]

        logging.info(f'Running analysis with the following set of '
                     f'callbacks: {callbacks}')

    kernel_fn = get_kernel_fn(args.kernel)

    diffusion_condensation = DiffusionCondensation(
        callbacks=callbacks,
        kernel_fn=kernel_fn
    )
    data = diffusion_condensation(X, args.epsilon)

    logging.info(f'Storing results in {output_filename}')
    np.savez(output_filename, **data)
